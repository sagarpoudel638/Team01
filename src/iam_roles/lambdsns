import boto3
import csv
from io import StringIO, BytesIO
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
import gzip
import os

def lambda_handler(event, context):
    iam_roles = list_iam_roles()
    role_function_mapping = map_roles_to_lambda_functions(iam_roles)
    bucket_name = os.getenv('BUCKET_NAME', 'team1reportbucket')  # Using environment variables for configuration
    report_period = os.getenv('REPORT_PERIOD', '20240301-20240401')
    folder = f"report/mycostreport/{report_period}/"
    file_key = folder + "20240315T100631Z/mycostreport-00001.csv.gz"
    cost_data = generate_cost_data(role_function_mapping, bucket_name, file_key)
    print(cost_data)  # For debugging purposes
    send_to_prometheus(cost_data)

def list_iam_roles():
    iam_client = boto3.client('iam')
    iam_roles = []
    paginator = iam_client.get_paginator('list_roles')
    for page in paginator.paginate():
        for role in page['Roles']:
            iam_roles.append(role['RoleName'])
    return iam_roles

def map_roles_to_lambda_functions(iam_roles):
    lambda_client = boto3.client('lambda')
    role_function_mapping = []
    paginator = lambda_client.get_paginator('list_functions')
    for page in paginator.paginate():
        for function in page['Functions']:
            for role in iam_roles:
                if function['Role'].split('/')[-1] == role:  # Extracting role name from ARN
                    role_function_mapping.append({
                        "RoleName": role,
                        "FunctionName": function['FunctionName'],
                    })
    return role_function_mapping

def generate_cost_data(role_function_mapping, bucket_name, file_key):
    csv_content = download_and_decompress_csv(bucket_name, file_key)
    csv_reader = csv.DictReader(StringIO(csv_content))
    role_cost_data = {mapping['RoleName']: {'TotalCost': 0, 'Services': {}} for mapping in role_function_mapping}

    for row in csv_reader:
        service_name = None
        if row['lineItem/ProductCode'] == 'AWSLambda':
            service_name = 'Lambda'
        elif row['lineItem/ProductCode'] == 'AmazonSNS':
            service_name = 'SNS'
            
        if service_name:
            cost = float(row['lineItem/UnblendedCost'])
            start_date = row['lineItem/UsageStartDate']
            for mapping in role_function_mapping:
                if service_name == 'Lambda' and mapping['FunctionName'] in row['lineItem/ResourceId']:
                    role_name = mapping['RoleName']
                    function_name = mapping['FunctionName']
                    break
                elif service_name == 'SNS':
                    print(f"!!!!!!!!!!!!!!THIS IS BEING EXECUTED!!!!!!!!!!!!!!")
                    role_name = mapping['RoleName']
                    function_name = 'SNS'  # Using 'SNS' as a placeholder function name for SNS costs
                    break
            else:
                continue  # Skip to the next row if no mapping was found

            service_data = role_cost_data[role_name].setdefault('Services', {}).setdefault(service_name, {'TotalCost': 0, 'Functions': {}})
            function_data = service_data['Functions'].setdefault(function_name, [])
            function_data.append({'StartDate': start_date, 'Cost': cost})
            role_cost_data[role_name]['TotalCost'] += cost
            service_data['TotalCost'] += cost

    # Optional: Sort and further process the data if necessary

    return role_cost_data

def download_and_decompress_csv(bucket_name, file_key):
    s3_client = boto3.client('s3')
    response = s3_client.get_object(Bucket=bucket_name, Key=file_key)
    with gzip.GzipFile(fileobj=BytesIO(response['Body'].read())) as gz:
        file_content = gz.read().decode('utf-8')
    return file_content

def send_to_prometheus(cost_data):
    registry = CollectorRegistry()
    cost_gauge = Gauge(
        'aws_service_cost',
        'Cost of AWS services by role and function',
        ['role_name', 'service_name', 'function_name', 'start_date'],
        registry=registry,
    )

    for role_name, role_data in cost_data.items():
        for service_name, service_data in role_data['Services'].items():
                        for function_name, costs in service_data["Functions"].items():
                            for cost_entry in costs:
                                cost_gauge.labels(
                                    role_name=role_name,
                                    service_name=service_name,
                                    function_name=function_name,
                                    start_date=cost_entry["StartDate"]
                                ).set(cost_entry["Cost"])

    # Push the metrics to the Pushgateway
    push_to_gateway(
        os.environ["prometheus_ip"], job="aws_service_costs", registry=registry
    )
    print("Data successfully pushed to Prometheus Pushgateway.")

